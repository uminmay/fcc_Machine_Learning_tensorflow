{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cafd80-9956-494b-b764-c80f82cd0b20",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6637-df33-4a0d-9bc2-dffd4a1f32d3",
   "metadata": {},
   "source": [
    "### RNNs to\n",
    "- Sentiment Analysis\n",
    "- Character/Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddbbbc-9d77-4894-8ed1-b0b3450016a8",
   "metadata": {},
   "source": [
    "<-> Recurrent Neural Network other than (-) CNN or Dense() is that it contains an internal loop, doesnot process the entire data at once, process it at different steps and maintains a memory (internal state) and uses it to put new input. Next word based on the previous word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee37a4-48ec-4c29-80a8-6a1ca994b8de",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928b4666-c07d-4dbf-a11f-ffdbd86733d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 26s 1us/step\n",
      "17473536/17464789 [==============================] - 26s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "D:\\Programs\\conda3\\lib\\site-packages\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\Programs\\conda3\\lib\\site-packages\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac14f81-ef6c-4fa5-a7de-01f3b123f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab03f6-e831-47f7-81ce-4a70394d845e",
   "metadata": {},
   "source": [
    "### More Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2da7fc7-8450-4b60-8f7e-a0b354857968",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd06ce4-d90d-4582-9b45-cad0047be212",
   "metadata": {},
   "source": [
    "Make all same length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a0e8f-957e-4584-a56c-f75953238c56",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1fe5e48-a188-4e85-8607-64da045edb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([ \\\n",
    "                            tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "                            tf.keras.layers.LSTM(32),\n",
    "                            tf.keras.layers.Dense(1, activation=\"sigmoid\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62b2233-f6f2-4e79-8404-55b1206731b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          2834688   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3f850-0e9b-4f28-bd90-3deff6c5b3a2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5201a2-ecd4-4a00-9676-9ad94917239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 92s 136ms/step - loss: 0.4236 - acc: 0.8058 - val_loss: 0.2919 - val_acc: 0.8862\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 91s 146ms/step - loss: 0.2390 - acc: 0.9079 - val_loss: 0.2748 - val_acc: 0.8874\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 82s 131ms/step - loss: 0.1845 - acc: 0.9334 - val_loss: 0.2779 - val_acc: 0.8958\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.1536 - acc: 0.9470 - val_loss: 0.2856 - val_acc: 0.8936\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 97s 156ms/step - loss: 0.1284 - acc: 0.9539 - val_loss: 0.3032 - val_acc: 0.8934\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 101s 161ms/step - loss: 0.1118 - acc: 0.9610 - val_loss: 0.2997 - val_acc: 0.8928\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 0.0967 - acc: 0.9676 - val_loss: 0.3337 - val_acc: 0.8916\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 92s 148ms/step - loss: 0.0884 - acc: 0.9703 - val_loss: 0.3691 - val_acc: 0.8842\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 109s 175ms/step - loss: 0.0777 - acc: 0.9748 - val_loss: 0.3734 - val_acc: 0.8872\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 106s 170ms/step - loss: 0.0685 - acc: 0.9776 - val_loss: 0.3869 - val_acc: 0.8878\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3bb5204-8029-4680-a7a3-7405f9bb66fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 32s 41ms/step - loss: 0.4867 - acc: 0.8568\n",
      "[0.48671820759773254, 0.8568000197410583]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd959ff0-19ea-41a3-93d4-194ec9abd9b2",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2318572-332c-4d72-b918-9b10cccff587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"that movie was just amazing, so amazing\"\n",
    "encode = encode_text(text)\n",
    "print(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70f265c-25db-4e1c-9032-1ad02fe1325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "### the decode function\n",
    "reverse_word_index = {value: key for (key,value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "    return text[:-1]\n",
    "print(decode_integers(encode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57fd38-5bd8-4bd4-b516-b65541378dc4",
   "metadata": {},
   "source": [
    "### The prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed3b8c04-97d6-4fd5-88e3-657cbc34b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5558649]\n",
      "[0.564133]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])\n",
    "    \n",
    "positive_rev = \"That movie was good and great! I really loreverse_word_indexnd watch it again because it was amazingly great\"\n",
    "predict(positive_rev)\n",
    "negative_rev = \"That movie sucked. I hated it and would not watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26505b3c-8002-46a5-9408-757c5f408602",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STRANGE OUTPUTS... NEED TO REVISIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780dd27-b35e-4dbe-866d-dbf032a15a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
